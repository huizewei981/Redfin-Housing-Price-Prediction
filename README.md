# Redfin-Housing-Price-Prediction

Our primary goal for this product is to quantify the returns on investment of the properties with advanced statistical, machine learning and time series forecast techniques that our customers can make comparisons between different locations, types of properties and then find the most appropriate one.  After implementing our analysis, customers will now get a better understanding of the housing market trend across different states and cities, further they will be able to wisely make investment decisions. In addition, by providing customers with proper zip code and housing types they should be able to have more targeted goals when looking for an investment home. We will use our existing workflows within the organization to ensure seamless transitions between different teams and ensure the success of our product. 

Primary objective: 

Build a comprehensive analytics platform for the real estate investors while harnessing the power of data and predictive analytics. 

Data:

The data that we are using in this project is the housing information from Redfin. We scrape all housing information of the sold properties with the past 5 years from Redfin, while in order to keep the completeness of the data (i.e. avoid missing sales data for any months), we only provide analysis on three different housing types (Condo/Single Family/Townhouse) that are most popular. Our product was designed to scrape the housing information based on the zip codes provided by the users, while for demonstration purposes, we use 10+ different zip codes in the south bay area. The target variables are different for each of the steps we designed to get the final output. The first step where we gathered the housing data and put it into a time-series prediction model, the target output is zip code. In our second step we use the previous zip code which gives the highest return on investment to further make predictions on property types and find the type that’s highest on ROI, in this case, the target variable is property type. The last step where we built a non-time series predictive model to predict listing prices, the target variable here is price. More details will be provided in the ‘Types of Analytics’ section.
By conducting exploratory data analysis, we further identified some pricing patterns for each zip code and property types, we also dropped columns that are not used and formatted the dataset for the next step. Since our data is time-series sensitive, we are very careful when handling the null values and making sure we keep the original data as consistent as possible. 

- Types of Analytics:
As mentioned in the ‘Data’  section, we performed both predictive analytics and exploratory (descriptive) analytics throughout our projects. More specifically, both time-series modeling and non time-series modeling can be found in our project. Here, we will mainly focus on predictive modeling. 

Predictive Analytics:

- Time Series Predictive Analytics:

The first two steps in our pipeline will require time series predictive analysis. In the first step, we use the housing information to find the zip code with the highest return, here we build a SARIMA model to make predictions for each zip code and get an estimated monthly forecast of housing price for the next 1, 3 and 5 years. We split the data into train and test based on the time order (instead of randomly selecting). According to the season-decomposition graph, we observe a 12-month cycle and therefore set seasonality to be 12. In regard to how to find the best q, p, d and Q, P, D, we use Grid Search, which means that we try every combination of 0 and 1 for these 6 parameters and identify the best model with the lowest Akaike information criterion (AIC) score. After running the tuned model, we use the CAGR to calculate compounded return on investment for each zip code and pick out the one with highest CAGR for the next step. 
In the second step, knowing which zip code will bring us the highest return, we leverage that to further dig deep into the property type. Based on the property type, we utilize SARIMA and Holt-winters filter model to conduct time aries prediction on housing price for the next 3 years and based on that we get another set of returns per property type. We also tried to use recurrent neural networks (RNN) but it turns out that due to running issues we couldn’t get the desired results as we get from the other models. 

- Non Time Series Predictive Analytics:

The main objective of building non time series predictive models is to utilize the existing housing information on Redfin to predict current housing prices (i.e. if the user wants to invest in some properties in the near future, what price range is appropriate). As mentioned in the ‘Data’ section, we have information on property types, number of beds, baths, the sqrt and some other related information. Before building the models, data preprocessing is important. Since we are focusing on housing prices based on given factors, we did not include the time series variable in the model, instead, we converted the year and quarter information to dummy variables to separate and minimize the heteroskedasticity and autocorrelation issues caused by time. We also converted categorical variables such as property type to dummy variables. Furthermore, we split the data into 70% train and 30% test as well. The split is random instead of based on time order. We have tried linear regression, Lasso CV, Random Forest, and Gradient Boost on the train dataset and performed evaluation on the test dataset. We use R squared, mean absolute percentage error (MAPE) and mean absolute error (MAE) to evaluate and compare the performance of different models. The below graph shows the performance on the test dataset for all models, while the Gradient Boost model performed the best. 

Analytic - Next Step:
- Combine data from multiple sources instead of solely relying on Redfin. For example, we can also extract the housing data from Zillow and Trulia. In addition, we may also add more features from other web pages, such as the school rating, the surrounding hospital resources. One potential issue with too many platforms is that the format and available information might differ across platforms. In this case, we would need to get those housing information independently and aggregate required information only, such as sold price, property type, zip code, etc. With additional market resources, our analytics will be more robust in the long run.
- Add more zip code to the current dataset, cover more states and cities. This will increase the coverage of our business, as well as receiving customers from all over the states. 
- Add other features that may also affect the aggregate return on investment (e.g.  Expected Monthly Rental Income, Mortgage interest expenses, Real Estates Tax, etc.) and provide a more comprehensive report.
